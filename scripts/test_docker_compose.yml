services:
  mysql:
    image: mysql:8.0.29
    command: --default_authentication_plugin=mysql_native_password
    environment:
      MYSQL_ROOT_PASSWORD: root
    volumes:
      # 设置初始化脚本
      - ./mysql/init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "13316:3306"
    healthcheck:
      test: [ "CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "--password=root" ]
      interval: 2s
      timeout: 5s
      retries: 15
      start_period: 10s
    networks:
      default:
  redis:
    image: 'redislabs/rebloom:latest'
    command: redis-server --notify-keyspace-events AKE --loadmodule /usr/lib/redis/modules/redisbloom.so
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    ports:
      - '6379:6379'
    networks:
      default:
  kafka:
    image: 'bitnami/kafka:3.9.0'
    ports:
      - '9092:9092'
      - '9094:9094'
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9094,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
    networks:
      default:
  etcd:
    image: 'bitnami/etcd:latest'
    environment:
      - ALLOW_NONE_AUTHENTICATION=yes
      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379
    ports:
      #      客户端通信接口
      - 2379:2379
      #      集群节点通信端口
      - 2380:2380

#  prometheus:
#    image: prom/prometheus:latest
#    volumes:
#      #  - 将本地的 prometheus 文件映射到容器内的配置文件
#      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
#    ports:
#      #  - 访问数据的端口
#      - 9090:9090
#    command:
#      - "--web.enable-remote-write-receiver"
#      - "--config.file=/etc/prometheus/prometheus.yml"
#    extra_hosts:
#      - "host.docker.internal:host-gateway"
#  grafana:
#    image: grafana/grafana-enterprise:10.2.0
#    ports:
#      - 3000:3000
  zipkin:
  
    image: openzipkin/zipkin-slim:latest
    ports:
      - '9411:9411'

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      default:

  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    environment:
      - xpack.monitoring.enabled=false
    ports:
      - "5001:5000"
      - "9600:9600"
    volumes:
#      如果不用filebeat采集日志就需要将日志映射到容器中
      - ../logs:/logs
      - ./logstash/pipeline:/usr/share/logstash/pipeline
    depends_on:
      - elasticsearch
    networks:
      default:

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      default:

  canal:
    image: canal/canal-server:v1.1.8
    depends_on:
      mysql:
        condition: service_healthy
        restart: true
    ports:
      - "11111:11111"
    environment:
      CANAL_USER: canal
      CANAL_PASSWORD: canal_pass
      CANAL_DESTINATION: permission
    volumes:
      - ./canal/instance.properties:/opt/canal-server/conf/permission/instance.properties
    networks:
      - default

volumes:
  esdata:
    driver: local